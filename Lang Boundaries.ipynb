{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a) Using one of the Corpora in the last lab. Calculate the average \"Tokens\" per sentence.\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "movie_text = movie_reviews.raw()\n",
    "tokens = nltk.sent_tokenize(movie_text)\n",
    "counts=0\n",
    "\n",
    "\n",
    "def avg_movie():\n",
    "    sentences = nltk.sent_tokenize(movie_text)\n",
    "    counts = (len(nltk.word_tokenize(sentence)) for sentence in sentences)\n",
    "    return sum(counts)/float(len(sentences))\n",
    "\n",
    "output = avg_movie()\n",
    "print(\"Average number of tokens per sentence in the movie review corpus: {:.2f}\".format(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1b) Using the same or different corpus, which category \n",
    "#has the longest sentences on average, which has the shortest?\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "sentences = sent_tokenize(movie_text)\n",
    "word_count = lambda sentence: sum((len(nltk.word_tokenize(sentence)) for sentence in sentences))/float(len(sentences))\n",
    "print(\"Shortest sentence by word count\")\n",
    "print(min(sentences, key=word_count)) # the shortest sentence by word count\n",
    "print(\"Longest sentence by word count\")\n",
    "print(max(sentences, key=word_count)) # the longest sentence by word count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4367\n"
     ]
    }
   ],
   "source": [
    "#2a)How many sentences are in the document (use NLTK to split the sentences)? \n",
    "#How does this differ from the amount of lines in the file (readlines)?\n",
    "#Downloaded this corpus from gutenberg: https://www.gutenberg.org/ebooks/19142\n",
    "#Download your own \"Corpus\" on https://www.gutenberg.org/ (Links to an external site.) \n",
    "\n",
    "import nltk\n",
    "file_content = open(\"devilbook_long.txt\").read()\n",
    "tokens_text = nltk.sent_tokenize(file_content)\n",
    "#print(tokens)\n",
    "sentence_count=0\n",
    "for sentence in tokens_text:\n",
    "    tokenized_text = nltk.sent_tokenize(sentence)\n",
    "    tagged = nltk.pos_tag(tokenized_text)\n",
    "    sentence_count= sentence_count + 1\n",
    "    \n",
    "print(sentence_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10057\n"
     ]
    }
   ],
   "source": [
    "#this is using readline method to count the lines of the devil book\n",
    "reviews = []\n",
    "count= 0\n",
    "with open('devilbook_long.txt', 'r') as devilbook:\n",
    "    count = sum(1 for _ in devilbook)\n",
    "    #reviews = ([(review, 'good_review') for review in devilbook.readlines()])\n",
    "#print(reviews)\n",
    "print(count)\n",
    "\n",
    "#How does this differ from the amount of lines in the file (readlines)?\n",
    "#the corpus method using tokenize is 4367 compared to 10057 for the readlines method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ï»¿The Project Gutenberg EBook of The Devil Doctor, by Sax Rohmer\\n\\nThis eBook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.', 'NN')]\n",
      "[('You may copy it, give it away or\\nre-use it under the terms of the Project Gutenberg License included\\nwith this eBook or online at www.gutenberg.org\\n\\n\\nTitle: The Devil Doctor\\n\\nAuthor: Sax Rohmer\\n\\nRelease Date: August 29, 2006 [EBook #19142]\\n\\nLanguage: English\\n\\n\\n*** START OF THIS PROJECT GUTENBERG EBOOK THE DEVIL DOCTOR ***\\n\\n\\n\\n\\nProduced by David Clarke, Sankar Viswanathan, and the\\nOnline Distributed Proofreading Team at http://www.pgdp.net\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                 THE\\n                             DEVIL DOCTOR\\n\\n\\n\\n                  HITHERTO UNPUBLISHED ADVENTURES IN\\n                     THE CAREER OF THE MYSTERIOUS\\n                            DR. FU-MANCHU\\n\\n\\n                                  BY\\n\\n\\n                              SAX ROHMER\\n\\n\\n\\n                            SIXTH EDITION\\n\\n\\n\\n                          METHUEN & CO. LTD.\\n                         36 ESSEX STREET W.C.\\n                                LONDON\\n\\n\\n\\n            _First Published (Crown 8vo) March 2nd, 1916_\\n\\n       *       *       *       *       *\\n\\n\\n\\n\\nCONTENTS\\n\\n\\nCHAP.', 'NN')]\n",
      "[('I       A MIDNIGHT SUMMONS\\n\\nII      ELTHAM VANISHES\\n\\nIII     THE WIRE JACKET\\n\\nIV      THE CRY OF A NIGHTHAWK\\n\\nV       THE NET\\n\\nVI      UNDER THE ELMS\\n\\nVII     ENTER MR. ABEL SLATTIN\\n\\nVIII    DR. FU-MANCHU STRIKES\\n\\nIX      THE CLIMBER\\n\\nX       THE CLIMBER RETURNS\\n\\nXI      THE WHITE PEACOCK\\n\\nXII     DARK EYES LOOK INTO MINE\\n\\nXIII    THE SACRED ORDER\\n\\nXIV     THE COUGHING HORROR\\n\\nXV      BEWITCHMENT\\n\\nXVI     THE QUESTING HANDS\\n\\nXVII    ONE DAY IN RANGOON\\n\\nXVIII   THE SILVER BUDDHA\\n\\nXIX     DR. FU-MANCHU\\'S LABORATORY\\n\\nXX      THE CROSSBAR\\n\\nXXI     CRAGMIRE TOWER\\n\\nXXII    THE MULATTO\\n\\nXXIII   A CRY ON THE MOOR\\n\\nXXIV    STORY OF THE GABLES\\n\\nXXV     THE BELLS\\n\\nXXVI    THE FIERY HAND\\n\\nXXVII   THE NIGHT OF THE RAID\\n\\nXXVIII  THE SAMURAI\\'S SWORD\\n\\nXXIX    THE SIX GATES\\n\\nXXX     THE CALL OF THE EAST\\n\\nXXXI    \"MY SHADOW LIES UPON YOU\"\\n\\nXXXII   THE TRAGEDY\\n\\nXXXIII  THE MUMMY\\n\\n       *       *       *       *       *\\n\\n\\n\\n\\nTHE DEVIL DOCTOR\\n\\nCHAPTER I\\n\\nA MIDNIGHT SUMMONS\\n\\n\\n\"When did you last hear from Nayland Smith?\"', 'NN')]\n",
      "[('asked my visitor.', 'NN')]\n",
      "[('I paused, my hand on the siphon, reflecting for a moment.', 'NN')]\n",
      "[('\"Two months ago,\" I said: \"he\\'s a poor correspondent and rather\\nsoured, I fancy.\"', 'NN')]\n",
      "[('\"What--a woman or something?\"', 'NN')]\n",
      "[('\"Some affair of that sort.', 'NN')]\n",
      "[('He\\'s such a reticent beggar, I really know\\nvery little about it.\"', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "#After tokenizing the sentences, find 3 errors and describe why you think \n",
    "#this error might of occurred. What in the algorithm might have gone wrong?\n",
    "\n",
    "import nltk\n",
    "file_content = open(\"devilbook.txt\").read()\n",
    "tokens_text = nltk.sent_tokenize(file_content)\n",
    "#print(tokens)\n",
    "sentence_count=0\n",
    "for sentence in tokens_text:\n",
    "    tokenized_text = nltk.sent_tokenize(sentence)\n",
    "    tagged = nltk.pos_tag(tokenized_text)\n",
    "    sentence_count= sentence_count + 1\n",
    "    \n",
    "    print(tagged)\n",
    "\n",
    "#there are some uneeded brackets like [( and \\n ,the formatting is overall broken and messy when ran\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-37-0c5e339a5cc0>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-37-0c5e339a5cc0>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    reviews = ([for review in devilbook.readlines()])\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
